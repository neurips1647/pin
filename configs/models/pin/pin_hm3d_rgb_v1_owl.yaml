# @package _global_

defaults:
  - /habitat: habitat_config_base
  - /habitat/task: pin
  - /habitat/simulator/agents@habitat.simulator.agents.main_agent: rgbds_agent
  - /habitat/dataset/pin: hm3d
  - _self_
# override existing config elements

habitat:
  dataset:
    split: train
    data_path: data/datasets/pin/hm3d/v1/{split}/{split}.json.gz
  environment:
    max_episode_steps: 1000
    iterator_options:
      shuffle: False
      max_scene_repeat_steps: -1
  seed: 1
  simulator:
    habitat_sim_v0:
      allow_sliding: True
    forward_step_size: 0.25
    turn_angle: 30
    tilt_angle: 30
    action_space_config: v1
    agents:
      main_agent:
        sim_sensors:
          rgb_sensor:
            width: 360
            height: 640
            hfov: 42
            position: [0, 1.31, 0]
          depth_sensor:
            width: 360
            height: 640
            hfov: 42
            min_depth: 0.5
            max_depth: 5.0
            position: [0, 1.31, 0]
          semantic_sensor:
            width: 360
            height: 640
            hfov: 42
            position: [0, 1.31, 0]
        height: 1.41
        radius: 0.17

semantic_map:
  map_size_cm: 4800                 # global map size (in centimeters)
  map_resolution: 5                 # size of map bins (in centimeters)
  vision_range: 100                 # diameter of local map region visible by the agent (in cells)
  explored_radius: 50              # radius (in centimeters) of visually explored region
  been_close_to_radius: 200         # radius (in centimeters) of been close to region
  global_downscaling: 2             # ratio of global over local map
  du_scale: 4                       # frame downscaling before projecting to point cloud
  cat_pred_threshold: 5.0           # number of depth points to be in bin to classify it as a certain semantic category
  exp_pred_threshold: 1.0           # number of depth points to be in bin to consider it as explored
  map_pred_threshold: 1.0           # number of depth points to be in bin to consider it as obstacle
  num_sem_categories: 1
  must_explore_close: False
  min_obs_height_cm: 10             # minimum height (in centimeters) of obstacle to be considered as obstacle
  # erosion and filtering to reduce the number of spurious artifacts
  dilate_obstacles: False
  dilate_size: 3
  dilate_iter: 1
planner:
  collision_threshold: 0.20         # forward move distance under which we consider there's a collision (in meters)
  step_size: 5                      # maximum distance of the short-term goal selected by the planner
  obs_dilation_selem_radius: 3      # radius (in cells) of obstacle dilation structuring element
  goal_dilation_selem_radius: 11    # radius (in cells) of goal dilation structuring element
  min_obs_dilation_selem_radius: 3  # min radius (in cells) of obstacle dilation structuring element
  map_downsample_factor: 1          # optional downsampling of traversible and goal map before fmm distance call (1 for no downsampling, 2 for halving resolution)
  map_update_frequency: 1           # compute fmm distance map every n steps 
  discrete_actions: True            # discrete motion planner output space or not
  use_dilation_for_stg: True        # use dilated goals for estimating short-term goals - or just reaching
  verbose: False                    # display debug information during planning
semantic_prediction:
  depth_filtering: True
  depth_filter_range_cm: 100        # 1m about the depth median (+/- 50cm)
  goal_filtering: True              # filter out outlier points in the goal map w/ DBSCAN
cow:
  clip_model_name: ViT-B/32
  classes: ['backpack', 'bag', 'ball', 'book', 'camera', 'cellphone', 'eyeglasses', 'hat', 'headphones', 'keys', 'laptop', 'mug', 'shoes', 'teddy_bear', 'toy', 'visor', 'wallet', 'watch']
  classes_clip: ['backpack', 'bag', 'ball', 'book', 'camera', 'cellphone', 'eyeglasses', 'hat', 'headphones', 'keys', 'laptop', 'mug', 'shoes', 'teddy bear', 'toy', 'visor', 'wallet', 'watch']
  templates: ['a bad photo of a {}.',
    'a photo of many {}.',
    'a sculpture of a {}.',
    'a photo of the hard to see {}.',
    'a low resolution photo of the {}.',
    'a rendering of a {}.',
    'graffiti of a {}.',
    'a bad photo of the {}.',
    'a cropped photo of the {}.',
    'a tattoo of a {}.',
    'the embroidered {}.',
    'a photo of a hard to see {}.',
    'a bright photo of a {}.',
    'a photo of a clean {}.',
    'a photo of a dirty {}.',
    'a dark photo of the {}.',
    'a drawing of a {}.',
    'a photo of my {}.',
    'the plastic {}.',
    'a photo of the cool {}.',
    'a close-up photo of a {}.',
    'a black and white photo of the {}.',
    'a painting of the {}.',
    'a painting of a {}.',
    'a pixelated photo of the {}.',
    'a sculpture of the {}.',
    'a bright photo of the {}.',
    'a cropped photo of a {}.',
    'a plastic {}.',
    'a photo of the dirty {}.',
    'a jpeg corrupted photo of a {}.',
    'a blurry photo of the {}.',
    'a photo of the {}.',
    'a good photo of the {}.',
    'a rendering of the {}.',
    'a {} in a video game.',
    'a photo of one {}.',
    'a doodle of a {}.',
    'a close-up photo of the {}.',
    'a photo of a {}.',
    'the origami {}.',
    'the {} in a video game.',
    'a sketch of a {}.',
    'a doodle of the {}.',
    'a origami {}.',
    'a low resolution photo of a {}.',
    'the toy {}.',
    'a rendition of the {}.',
    'a photo of the clean {}.',
    'a photo of a large {}.',
    'a rendition of a {}.',
    'a photo of a nice {}.',
    'a photo of a weird {}.',
    'a blurry photo of a {}.',
    'a cartoon {}.',
    'art of a {}.',
    'a sketch of the {}.',
    'a embroidered {}.',
    'a pixelated photo of a {}.',
    'itap of the {}.',
    'a jpeg corrupted photo of the {}.',
    'a good photo of a {}.',
    'a plushie {}.',
    'a photo of the nice {}.',
    'a photo of the small {}.',
    'a photo of the weird {}.',
    'the cartoon {}.',
    'art of the {}.',
    'a drawing of the {}.',
    'a photo of the large {}.',
    'a black and white photo of a {}.',
    'the plushie {}.',
    'a dark photo of a {}.',
    'itap of a {}.',
    'graffiti of the {}.',
    'a toy {}.',
    'itap of my {}.',
    'a photo of a cool {}.',
    'a photo of a small {}.',
    'a tattoo of the {}.']
  threshold: 0.2
  center_only: true
  modality: "captions"
  min_matches: 1
  method: "owl"
  resize_dim: 224
exp_name: debug
num_environments: 1
simulator_gpu_id: 0
dump_location: dbg_imgs/pin
generate_videos: False
frame_width: 360
frame_height: 640
preprojection_kp_dilation: 4        # KP-based loc: how much to dilate keypoints prior to projection and aggregation
multiscale: False
scales: [30, 180]
